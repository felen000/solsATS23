
import cv2
import numpy as np

# Задаем координаты углов квадрата,
# в который будем преобразовывать прямоугольное изображение найденных грузов
sdr = np.float32([
    [0, 0],
    [300, 0],
    [0, 300],
    [300, 300]
])

font = cv2.FONT_HERSHEY_COMPLEX  # шрифт для подписей на изображении

cap = cv2.VideoCapture(0)  # Инициализация работы с камерой

i = 0  #  счётчик кадров
while i < 20:  # цикл обработки первых 20 кадров
    ret, frame = cap.read()  # чтение кадра с камеры
    if not ret:
        break

    img = cv2.resize(frame, (480, 400))  # изменяем размер изображения
    img = img[:250, :]  # оставляем изображение только зоны разгрузки
    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # переводим изображение в HSV формат
    # зона разгрузки имеет преимущественно чёрный цвет
    # бинаризуем изображение так, чтобы грузы и цветные полосы стали белыми,
    # а фон стал чёрным
    black_m = cv2.inRange(img, (55, 55, 55), (255, 255, 255))
    # бинаризуем HSV-изображение так, чтобы цветные полосы стали чёрными, а фон и грузы белым
    binimg = cv2.inRange(hsv_img, (0, 0, 0), (255, 140, 255))
    # находим пересечение масок, на нём останутся только очертания грузов
    binimg = cv2.bitwise_and(binimg, black_m)
    # ищем на изображении контуры
    contours, _ = cv2.findContours(binimg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    # сортируем контуры по убыванию площади
    contours = sorted(contours, key=cv2.contourArea, reverse=True)

    # Создаём списки для хранения координат центров уже обнаруженных грузов
    x_coordinates = []
    y_coordinates = []

    # Перебираем все обнаруженные контуры и проверяем, соответствует ли их размер заданным параметрам для груза
    for j in range(len(contours)):
        (x, y, w, h) = cv2.boundingRect(contours[j])
        #  Высота и ширина контура должны лежать в определённых пределах и
        #  не сильно отличаться друг от друга, т.е. быть близким к квадрату
        if 25 < w < 60 and 25 < h < 60 and abs(w - h) <= 7:
            # Устанавливаем флаг, обнаружения груза
            # Если контур соответствует уже детектированному грузу, то флаг = True
            same = False
            # сравниваем координаты "центра" контура с координатами "центров" уже обнаруженных грузов
            for ii in range(len(x_coordinates)):
                if abs((x + w // 2) - x_coordinates[ii]) < 10 and abs((y + h // 2) - y_coordinates[ii]) < 10:
                    # если центры ближе 10 пикселей по вертикали и
                    # ближе 10 пикселей по горизонтали, то контур указывает на уже обнаруженный груз
                    same = True  # выставляем соответствующий флаг
                    break  # прекращаем перебор координат уже найденных грузов

            # Если контур указывает на ранее не обнаруженый груз, то распознайм его маркировку.
            if not same:
                # сохраняем координаты центра груза
                x_coordinates.append(x + w // 2)
                y_coordinates.append(y + h // 2)

                # Находим минимальный прямоугольник, описывающий контур. Он может быть наклонён!
                rect = cv2.minAreaRect(contours[j])

                # получаем координаты верши прямоугольника
                # координаты преобразуются для передачи в функцию вычисления матрицы преобразования
                box = cv2.boxPoints(rect)
                box = np.int0(box)
                box = list(box)
                box[2], box[3] = box[3], box[2]
                box = np.float32(box)
                # переобразуем прямоугольник в кавдрат, для этого
                mm = cv2.getPerspectiveTransform(box, sdr)  # вычисляем матрицу преобразования
                # применяем матрицу к изображению, на выходе получаем горизонтально ориенитрованное изображение груза
                marker = cv2.warpPerspective(img, mm, (300, 300), flags=cv2.INTER_LINEAR)

                # Создаем несколько масок бинаризации для каждого возможного цвета полос маркировки, кроме чёрного
                # Маска - бинаризованное изображение, где белые пиксели соответствую конкретному цвету
                red_mask = cv2.inRange(marker, (0, 0, 140), (90, 110, 255))  # для красных полосы
                green_mask = cv2.inRange(marker, (50, 110, 0), (180, 255, 90))  # для зелёны полосы
                blue_mask = cv2.inRange(marker, (180, 90, 0), (255, 210, 100))  # для синих полосы
                white_mask = cv2.inRange(marker, (230, 230, 230), (255, 255, 255))  # для белых полосы

                # объединяем все маски, на результирующем изображении белые пиксели соответствуют полосам маркировки
                mask = cv2.bitwise_or(green_mask, red_mask)
                mask = cv2.bitwise_or(blue_mask, mask)
                mask = cv2.bitwise_or(white_mask, mask)

                # на объединении масок ищем контуры
                contours1, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                # сортируем контуры по убыванию площади
                contours1 = sorted(contours1, key=cv2.contourArea, reverse=True)


                min_dist = 300  # переменная для хранения минимальной дистанции от центра полосы до края изображения
                # Перебираем все найденные контуры, подходящие под размер полосы и
                # вычисляем координаты центра самой приблёжённой к краю изображения полосы
                # Эта полоса - кодирует первый символ маркировки, чтение нужно начинать с неё
                for k in range(len(contours1)):
                    # получаем координаты угла ограничивающего контур прямоугольника, его ширину и высоту
                    (x1, y1, w1, h1) = cv2.boundingRect(contours1[k])
                    if (w1 > 40 and h1 > 40):  # контур полосы должен быть больше определённого размера
                        cx = x1 + w1 // 2   # вычисляем координату центра полосы маркировки по х
                        cy = y1 + h1 // 2   # вычисляем координату центра полосы маркировки по y
                        # определяем минимальную дистанцию от центра полосы до стороны изображения
                        dist = min(cx, cy, 300 - cx, 300 - cy)
                        if min_dist >= dist:  # если полоса ближе всех к краю изображения, то
                            min_dist = dist   # обновляем минимальную дистанци,
                            cx_min = cx       # сохраняем координаты центра полосы по х
                            cy_min = cy       # и y


                # Поворачиваем изображение груза так, чтобы маркировка читалась слева на право
                # Вместе с изображением груза поворачиваем все соответствующие маски для полос разного цвета

                # Если расстояние от центра полосы до левого края изображения меньше чем расстояние до остальных краёв,
                if cx_min < cy_min and cx_min < 300 - cx_min and cx_min < 300 - cy_min:
                    # то изображение не нужно поворачивать
                    new_cx = cx_min  # сохраняем координаты центра первой полосы
                    new_cy = cy_min
                # Если расстояние от центра полосы до верхнего края изображения меньше
                # чем расстояние до остальных краёв,
                elif cy_min < cx_min and cy_min < 300 - cx_min and cy_min < 300 - cy_min:
                    # то поворачиваем изображение на 90 градусов против часовой стрелки
                    marker = cv2.rotate(marker, cv2.ROTATE_90_COUNTERCLOCKWISE)
                    red_mask = cv2.rotate(red_mask, cv2.ROTATE_90_COUNTERCLOCKWISE)
                    blue_mask = cv2.rotate(blue_mask, cv2.ROTATE_90_COUNTERCLOCKWISE)
                    green_mask = cv2.rotate(green_mask, cv2.ROTATE_90_COUNTERCLOCKWISE)
                    # пересчитываем координаты центра первой полосы в системе координат нового изображения 
                    new_cy = 300 - cx_min
                    new_cx = cy_min
                # Если расстояние от центра полосы до првого края изображения меньше
                # чем расстояние до остальных краёв,
                elif 300 - cx_min < cx_min and 300 - cx_min < cy_min and 300 - cx_min < 300 - cy_min:
                    # то поворачиваем изображение на 180 градусов
                    marker = cv2.rotate(marker, cv2.ROTATE_180)
                    red_mask = cv2.rotate(red_mask, cv2.ROTATE_180)
                    blue_mask = cv2.rotate(blue_mask, cv2.ROTATE_180)
                    green_mask = cv2.rotate(green_mask, cv2.ROTATE_180)
                    # пересчитываем координаты центра первой полосы в системе координат нового изображения
                    new_cx = 300 - cx_min
                    new_cy = 300 - cy_min
                else:
                    # Если расстояние от центра полосы до нижнего края изображения меньше
                    # чем расстояние до остальных краёв,
                    # то поворачиваем изображение на 90 градусов по часовой стрелке
                    marker = cv2.rotate(marker, cv2.ROTATE_90_CLOCKWISE)
                    red_mask = cv2.rotate(red_mask, cv2.ROTATE_90_CLOCKWISE)
                    blue_mask = cv2.rotate(blue_mask, cv2.ROTATE_90_CLOCKWISE)
                    green_mask = cv2.rotate(green_mask, cv2.ROTATE_90_CLOCKWISE)
                    # пересчитываем координаты центра первой полосы в системе координат нового изображения
                    new_cx = 300 - cy_min
                    new_cy = cx_min

                # Теперь изображение ориентированно так, что можно читать маркировку слева на право
                # Мы знаем координаты центра первой полосы, координаты центров остальных полос мы находим смещением
                # по оси х на 50 пикселей
                # Для каждой полосы в окрестности центра вычислется число белых пикселей на маске конкретного цвета,
                # по цвету маски где это число превышает некоторое значение определяем цвет полосы
                # и кодируемый ей символ
                name_mark = ""  # переменная для расшифровки маркировки
                for i in range(3):  # Просматриваем окрестности центров трёх полос
                    shift = i * 50  # смещение центра по оси х в зависимости от номера полосы

                    # Если на красной маске по координатам центра полосы есть белые пиксели, то
                    if np.sum(red_mask[new_cy - 5:new_cy + 5, shift + new_cx - 5:shift + new_cx + 5]) > 255 * 50:
                        name_mark += "R"  # полоса красная и кодирует символ "R", добавляем его к расшифровке
                    # Если на зелёной маске по координатам центра полосы есть белые пиксели, то
                    elif np.sum(green_mask[new_cy - 5:new_cy + 5, shift + new_cx - 5:shift + new_cx + 5]) > 50:
                        name_mark += "G"  # полоса зелёная и кодирует символ "G", добавляем его к расшифровке
                    # Если на синей маске по координатам центра полосы есть белые пиксели, то
                    elif np.sum(blue_mask[new_cy - 5:new_cy + 5, shift + new_cx - 5:shift + new_cx + 5]) > 50:
                        name_mark += "B"  # полоса синяя и кодирует символ "B", добавляем его к расшифровке
                    else:  # Если на масках не обнаружилось белых пикселей, значит
                        name_mark += "0"  # полоса белая или чёрная - кодирует "0", добавляем его к расшифровке

                # Отмечаем на изображении обнаруженный груз прямоугольником
                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)
                # добавляем над прямоугольникои подпись соответствующую расшифровке маркировки груза
                cv2.putText(img, name_mark, (x + 1, y - 4), font, 0.5, (0, 0, 255))

    key = cv2.waitKey(0)  # блокирующее чтение нажатой пользователем клавиши
    if key == ord('n'):  # Если нажата клавиша "n"
        cv2.destroyAllWindows()  # Уничтожаем все открытые программой окна
        i += 1   # Увеличиваем счётчик кадров
    if key == ord('q'):  # Если нажата клавиша "q"
        cv2.destroyAllWindows()  # Уничтожаем все открытые программой окна
        break  # Выходим из цикла обработки кадров и завершаем работу программы
